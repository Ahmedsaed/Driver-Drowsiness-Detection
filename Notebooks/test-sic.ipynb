{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mediapipe\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport mediapipe as mp\n\nos.makedirs('./yawn')\nos.makedirs('./no_yawn')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-05T20:19:27.618761Z","iopub.execute_input":"2022-11-05T20:19:27.619069Z","iopub.status.idle":"2022-11-05T20:19:27.870312Z","shell.execute_reply.started":"2022-11-05T20:19:27.619039Z","shell.execute_reply":"2022-11-05T20:19:27.869453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# labels","metadata":{}},{"cell_type":"code","source":"labels = os.listdir(\"../input/drowsiness-dataset/train\")\nlabels","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-11-05T20:19:28.098631Z","iopub.execute_input":"2022-11-05T20:19:28.098948Z","iopub.status.idle":"2022-11-05T20:19:28.109461Z","shell.execute_reply.started":"2022-11-05T20:19:28.098919Z","shell.execute_reply":"2022-11-05T20:19:28.108544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualize an image","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"../input/drowsiness-dataset/train/Closed/_1.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:19:31.002066Z","iopub.execute_input":"2022-11-05T20:19:31.002400Z","iopub.status.idle":"2022-11-05T20:19:31.274419Z","shell.execute_reply.started":"2022-11-05T20:19:31.002371Z","shell.execute_reply":"2022-11-05T20:19:31.273332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image shape","metadata":{}},{"cell_type":"code","source":"a = cv.imread(\"../input/drowsiness-dataset/train/Closed/_1.jpg\")\na.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mp_facemesh = mp.solutions.face_mesh\nmp_drawing  = mp.solutions.drawing_utils\ndenormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n \n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:19:53.859648Z","iopub.execute_input":"2022-11-05T20:19:53.859961Z","iopub.status.idle":"2022-11-05T20:20:09.286645Z","shell.execute_reply.started":"2022-11-05T20:19:53.859931Z","shell.execute_reply":"2022-11-05T20:20:09.285794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Landmark points corresponding to left eye\nall_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n# flatten and remove duplicates\nall_left_eye_idxs = set(np.ravel(all_left_eye_idxs)) \n \n# Landmark points corresponding to right eye\nall_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\nall_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n \n# Combined for plotting - Landmark points for both eye\nall_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n \n# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\nchosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\nchosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\nall_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs","metadata":{}},{"cell_type":"code","source":"# Landmark points corresponding to left eye\nall_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n# flatten and remove duplicates\nall_left_eye_idxs = set(np.ravel(all_left_eye_idxs)) \n \n# Landmark points corresponding to right eye\nall_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\nall_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n \n# Combined for plotting - Landmark points for both eye\nall_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n \n# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\nchosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\nchosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\nall_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:20:13.994358Z","iopub.execute_input":"2022-11-05T20:20:13.994722Z","iopub.status.idle":"2022-11-05T20:20:14.002746Z","shell.execute_reply.started":"2022-11-05T20:20:13.994689Z","shell.execute_reply":"2022-11-05T20:20:14.001612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(\n    *,n=1,\n    img_dt,cat,\n    img_eye_lmks=None,\n    img_eye_lmks_chosen=None,\n    face_landmarks=None,\n    ts_thickness=1,\n    ts_circle_radius=2,\n    lmk_circle_radius=3,\n    name=\"1\",\n):\n    # For plotting Face Tessellation\n    image_drawing_tool = img_dt \n     \n     # For plotting all eye landmarks\n    image_eye_lmks = img_dt.copy() if img_eye_lmks is None else img_eye_lmks\n     \n    # For plotting chosen eye landmarks\n    img_eye_lmks_chosen = img_dt.copy() if img_eye_lmks_chosen is None else img_eye_lmks_chosen\n \n    # Initializing drawing utilities for plotting face mesh tessellation\n    connections_drawing_spec = mp_drawing.DrawingSpec(\n        thickness=ts_thickness, \n        circle_radius=ts_circle_radius, \n        color=(255, 255, 255)\n    )\n \n    # Initialize a matplotlib figure.\n    fig = plt.figure(figsize=(20, 15))\n    fig.set_facecolor(\"white\")\n \n    # Draw landmarks on face using the drawing utilities.\n    mp_drawing.draw_landmarks(\n        image=image_drawing_tool,\n        landmark_list=face_landmarks,\n        connections=mp_facemesh.FACEMESH_TESSELATION,\n        landmark_drawing_spec=None,\n        connection_drawing_spec=connections_drawing_spec,\n    )\n \n    # Get the object which holds the x, y, and z coordinates for each landmark\n    landmarks = face_landmarks.landmark\n \n    # Iterate over all landmarks.\n    # If the landmark_idx is present in either all_idxs or all_chosen_idxs,\n    # get the denormalized coordinates and plot circles at those coordinates.\n \n    for landmark_idx, landmark in enumerate(landmarks):\n        if landmark_idx in all_idxs:\n            pred_cord = denormalize_coordinates(landmark.x, \n                                                landmark.y, \n                                                imgW, imgH)\n            cv2.circle(image_eye_lmks, \n                       pred_cord, \n                       lmk_circle_radius, \n                       (255, 255, 255), \n                       -1\n                       )\n \n        if landmark_idx in all_chosen_idxs:\n            pred_cord = denormalize_coordinates(landmark.x, \n                                                landmark.y, \n                                                imgW, imgH)\n            cv2.circle(img_eye_lmks_chosen, \n                       pred_cord, \n                       lmk_circle_radius, \n                       (255, 255, 255), \n                       -1\n                       )\n \n    # Plot post-processed images\n    plt.subplot(1, 3, 1)\n    plt.title(\"Face Mesh Tessellation \"+str(n), fontsize=18)\n    plt.imshow(image_drawing_tool)\n    if cat=='yawn':\n        cv2.imwrite(str('./yawn/'+str(n)+'.jpg'), image_drawing_tool)\n    else:\n        cv2.imwrite(str('./no_yawn/'+str(n)+'.jpg'), image_drawing_tool)\n    plt.axis(\"off\")\n \n    #plt.subplot(1, 3, 2)\n    #plt.title(\"All eye landmarks\", fontsize=18)\n    #plt.imshow(image_eye_lmks)\n    #plt.axis(\"off\")\n \n    #plt.subplot(1, 3, 3)\n    #plt.imshow(img_eye_lmks_chosen)\n    #plt.title(\"Chosen landmarks\", fontsize=18)\n    #plt.axis(\"off\")\n    #plt.show()\n    #plt.close()\n    return","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:20:29.196300Z","iopub.execute_input":"2022-11-05T20:20:29.196859Z","iopub.status.idle":"2022-11-05T20:20:29.216695Z","shell.execute_reply.started":"2022-11-05T20:20:29.196804Z","shell.execute_reply":"2022-11-05T20:20:29.215907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgH, imgW, _=0,0,0\n\ndef face_for_yawn(direc=\"../input/drowsiness-dataset/train\"):\n    i=1\n    yaw_no = []\n    IMG_SIZE = 145\n    categories = [\"yawn\", \"no_yawn\"]\n    for category in categories:\n        path_link = os.path.join(direc, category)\n        class_num1 = categories.index(category)\n        print(class_num1)\n        for image in os.listdir(path_link):\n            image = cv2.imread(os.path.join(path_link, image))\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert to RGB\n            image = np.ascontiguousarray(image)\n            imgH, imgW, _ = image.shape\n                             \n            # Running inference using static_image_mode \n            with mp_facemesh.FaceMesh(\n                static_image_mode=True,         # Default=False\n                max_num_faces=1,                # Default=1\n                refine_landmarks=False,         # Default=False\n                min_detection_confidence=0.5,   # Default=0.5\n                min_tracking_confidence= 0.5,) as face_mesh:\n\n                results = face_mesh.process(image)\n\n                # If detections are available.\n                if results.multi_face_landmarks:  \n                    # Iterate over detections of each face. Here, we have max_num_faces=1, \n                    # So there will be at most 1 element in \n                    # the 'results.multi_face_landmarks' list            \n                    # Only one iteration is performed.\n                    for face_id, face_landmarks in enumerate(results.multi_face_landmarks):    \n                        _ = plot(img_dt=image.copy(), cat=category, n=i ,face_landmarks=face_landmarks)\n                    i+=1\n                          \n    return ","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:21:37.870373Z","iopub.execute_input":"2022-11-05T20:21:37.870715Z","iopub.status.idle":"2022-11-05T20:21:37.881618Z","shell.execute_reply.started":"2022-11-05T20:21:37.870683Z","shell.execute_reply":"2022-11-05T20:21:37.880488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_for_yawn()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:21:40.357169Z","iopub.execute_input":"2022-11-05T20:21:40.357484Z","iopub.status.idle":"2022-11-05T20:25:33.507852Z","shell.execute_reply.started":"2022-11-05T20:21:40.357456Z","shell.execute_reply":"2022-11-05T20:25:33.507070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndir_path = r'./no_yawn'\nprint(len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:25:33.509805Z","iopub.execute_input":"2022-11-05T20:25:33.510062Z","iopub.status.idle":"2022-11-05T20:25:33.520837Z","shell.execute_reply.started":"2022-11-05T20:25:33.510035Z","shell.execute_reply":"2022-11-05T20:25:33.520004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndir_path = r'./yawn'\nprint(len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:25:33.522689Z","iopub.execute_input":"2022-11-05T20:25:33.522964Z","iopub.status.idle":"2022-11-05T20:25:33.533157Z","shell.execute_reply.started":"2022-11-05T20:25:33.522934Z","shell.execute_reply":"2022-11-05T20:25:33.532207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualize yawn image. \n# Here background is unnecessary. we need only face image array","metadata":{}},{"cell_type":"code","source":"plt.imshow(plt.imread(\"../input/drowsiness-dataset/train/yawn/10.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:52:52.075621Z","iopub.execute_input":"2022-11-05T20:52:52.075963Z","iopub.status.idle":"2022-11-05T20:52:52.261129Z","shell.execute_reply.started":"2022-11-05T20:52:52.075935Z","shell.execute_reply":"2022-11-05T20:52:52.260226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# for yawn and not_yawn. Take only face","metadata":{}},{"cell_type":"code","source":"def face_for_yawn(direc=\"./\", face_cas_path=\"../input/prediction-images/haarcascade_frontalface_default.xml\"):\n    yaw_no = []\n    IMG_SIZE = 145\n    categories = [\"yawn\", \"no_yawn\"]\n    for category in categories:\n        path_link = os.path.join(direc, category)\n        class_num1 = categories.index(category)\n        print(class_num1)\n        for image in os.listdir(path_link):\n            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n            face_cascade = cv2.CascadeClassifier(face_cas_path)\n            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n            for (x, y, w, h) in faces:\n                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n                roi_color = img[y:y+h, x:x+w]\n                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n                yaw_no.append([resized_array, class_num1])\n    return yaw_no\n\nyawn_no_yawn = face_for_yawn()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:53:01.693014Z","iopub.execute_input":"2022-11-05T20:53:01.693367Z","iopub.status.idle":"2022-11-05T20:55:07.078731Z","shell.execute_reply.started":"2022-11-05T20:53:01.693338Z","shell.execute_reply":"2022-11-05T20:55:07.077668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# for closed and open eye","metadata":{}},{"cell_type":"code","source":"def get_data(dir_path=\"../input/drowsiness-dataset/train/\", face_cas=\"../input/prediction-images/haarcascade_frontalface_default.xml\", eye_cas=\"../input/prediction-images/haarcascade.xml\"):\n    labels = ['Closed', 'Open']\n    IMG_SIZE = 145\n    data = []\n    for label in labels:\n        path = os.path.join(dir_path, label)\n        class_num = labels.index(label)\n        class_num +=2\n        print(class_num)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                data.append([resized_array, class_num])\n            except Exception as e:\n                print(e)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:58:32.653796Z","iopub.execute_input":"2022-11-05T20:58:32.654153Z","iopub.status.idle":"2022-11-05T20:58:32.661645Z","shell.execute_reply.started":"2022-11-05T20:58:32.654101Z","shell.execute_reply":"2022-11-05T20:58:32.660799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = get_data()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T20:58:34.431914Z","iopub.execute_input":"2022-11-05T20:58:34.432243Z","iopub.status.idle":"2022-11-05T20:58:44.316943Z","shell.execute_reply.started":"2022-11-05T20:58:34.432214Z","shell.execute_reply":"2022-11-05T20:58:44.315934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# extend data and convert array","metadata":{}},{"cell_type":"code","source":"def append_data():\n#     total_data = []\n    yaw_no = face_for_yawn()\n    data = get_data()\n    yaw_no.extend(data)\n    return np.array(yaw_no)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:05:12.549796Z","iopub.execute_input":"2022-11-05T21:05:12.550166Z","iopub.status.idle":"2022-11-05T21:05:12.555440Z","shell.execute_reply.started":"2022-11-05T21:05:12.550126Z","shell.execute_reply":"2022-11-05T21:05:12.554321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# new variable to store","metadata":{}},{"cell_type":"code","source":"new_data = append_data()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:05:19.235004Z","iopub.execute_input":"2022-11-05T21:05:19.235389Z","iopub.status.idle":"2022-11-05T21:07:30.221752Z","shell.execute_reply.started":"2022-11-05T21:05:19.235357Z","shell.execute_reply":"2022-11-05T21:07:30.220784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# separate label and features","metadata":{}},{"cell_type":"code","source":"X = []\ny = []\nfor feature, label in new_data:\n    X.append(feature)\n    y.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:30.225435Z","iopub.execute_input":"2022-11-05T21:07:30.225725Z","iopub.status.idle":"2022-11-05T21:07:30.234220Z","shell.execute_reply.started":"2022-11-05T21:07:30.225696Z","shell.execute_reply":"2022-11-05T21:07:30.233196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# reshape the array","metadata":{}},{"cell_type":"code","source":"X = np.array(X)\nX = X.reshape(-1, 145, 145, 3)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:30.235752Z","iopub.execute_input":"2022-11-05T21:07:30.236152Z","iopub.status.idle":"2022-11-05T21:07:30.274704Z","shell.execute_reply.started":"2022-11-05T21:07:30.236063Z","shell.execute_reply":"2022-11-05T21:07:30.273965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LabelBinarizer","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlabel_bin = LabelBinarizer()\ny = label_bin.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:30.276973Z","iopub.execute_input":"2022-11-05T21:07:30.277628Z","iopub.status.idle":"2022-11-05T21:07:30.930206Z","shell.execute_reply.started":"2022-11-05T21:07:30.277588Z","shell.execute_reply":"2022-11-05T21:07:30.929425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# label array","metadata":{}},{"cell_type":"code","source":"y = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:30.932464Z","iopub.execute_input":"2022-11-05T21:07:30.932729Z","iopub.status.idle":"2022-11-05T21:07:30.936404Z","shell.execute_reply.started":"2022-11-05T21:07:30.932704Z","shell.execute_reply":"2022-11-05T21:07:30.935541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train test split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nseed = 42\ntest_size = 0.30\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:30.937748Z","iopub.execute_input":"2022-11-05T21:07:30.938275Z","iopub.status.idle":"2022-11-05T21:07:31.020081Z","shell.execute_reply.started":"2022-11-05T21:07:30.938225Z","shell.execute_reply":"2022-11-05T21:07:31.019130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# length of X_test","metadata":{}},{"cell_type":"code","source":"len(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:31.021517Z","iopub.execute_input":"2022-11-05T21:07:31.021983Z","iopub.status.idle":"2022-11-05T21:07:31.027808Z","shell.execute_reply.started":"2022-11-05T21:07:31.021945Z","shell.execute_reply":"2022-11-05T21:07:31.026997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Not necessary, only use to matching with my pc version","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow==2.3.1\n# !pip install keras==2.4.3","metadata":{"execution":{"iopub.status.busy":"2022-11-05T15:59:54.390956Z","iopub.execute_input":"2022-11-05T15:59:54.391498Z","iopub.status.idle":"2022-11-05T15:59:54.396228Z","shell.execute_reply.started":"2022-11-05T15:59:54.391463Z","shell.execute_reply":"2022-11-05T15:59:54.395241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# import some dependencies","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:31.029043Z","iopub.execute_input":"2022-11-05T21:07:31.029546Z","iopub.status.idle":"2022-11-05T21:07:35.273432Z","shell.execute_reply.started":"2022-11-05T21:07:31.029510Z","shell.execute_reply":"2022-11-05T21:07:35.271610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# keras version","metadata":{}},{"cell_type":"code","source":"import keras","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:35.287984Z","iopub.execute_input":"2022-11-05T21:07:35.288356Z","iopub.status.idle":"2022-11-05T21:07:35.297853Z","shell.execute_reply.started":"2022-11-05T21:07:35.288320Z","shell.execute_reply":"2022-11-05T21:07:35.296979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"train_generator = ImageDataGenerator(rescale=1/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\ntest_generator = ImageDataGenerator(rescale=1/255)\n\ntrain_generator = train_generator.flow(np.array(X_train), y_train, shuffle=False)\ntest_generator = test_generator.flow(np.array(X_test), y_test, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T21:07:54.924748Z","iopub.execute_input":"2022-11-05T21:07:54.925100Z","iopub.status.idle":"2022-11-05T21:07:55.061480Z","shell.execute_reply.started":"2022-11-05T21:07:54.925065Z","shell.execute_reply":"2022-11-05T21:07:55.060410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:]))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:01:28.725415Z","iopub.execute_input":"2022-11-05T16:01:28.725793Z","iopub.status.idle":"2022-11-05T16:01:31.268964Z","shell.execute_reply.started":"2022-11-05T16:01:28.725754Z","shell.execute_reply":"2022-11-05T16:01:31.267104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, epochs=50, validation_data=test_generator, shuffle=True, validation_steps=len(test_generator))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:01:31.270391Z","iopub.execute_input":"2022-11-05T16:01:31.270737Z","iopub.status.idle":"2022-11-05T16:05:50.276173Z","shell.execute_reply.started":"2022-11-05T16:01:31.270694Z","shell.execute_reply":"2022-11-05T16:05:50.275258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# history","metadata":{}},{"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\nplt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, \"b\", label=\"trainning loss\")\nplt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:50.278903Z","iopub.execute_input":"2022-11-05T16:05:50.279241Z","iopub.status.idle":"2022-11-05T16:05:50.547437Z","shell.execute_reply.started":"2022-11-05T16:05:50.279210Z","shell.execute_reply":"2022-11-05T16:05:50.546702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save model","metadata":{}},{"cell_type":"code","source":"model.save(\"drowiness_new6.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:50.551018Z","iopub.execute_input":"2022-11-05T16:05:50.551293Z","iopub.status.idle":"2022-11-05T16:05:50.602666Z","shell.execute_reply.started":"2022-11-05T16:05:50.551264Z","shell.execute_reply":"2022-11-05T16:05:50.601888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"prediction = model.predict_classes(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:54.484525Z","iopub.execute_input":"2022-11-05T16:05:54.484823Z","iopub.status.idle":"2022-11-05T16:05:54.784669Z","shell.execute_reply.started":"2022-11-05T16:05:54.484795Z","shell.execute_reply":"2022-11-05T16:05:54.783725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:54.786224Z","iopub.execute_input":"2022-11-05T16:05:54.786573Z","iopub.status.idle":"2022-11-05T16:05:54.795744Z","shell.execute_reply.started":"2022-11-05T16:05:54.786536Z","shell.execute_reply":"2022-11-05T16:05:54.794779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# classification report","metadata":{}},{"cell_type":"code","source":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:54.797941Z","iopub.execute_input":"2022-11-05T16:05:54.798340Z","iopub.status.idle":"2022-11-05T16:05:54.803277Z","shell.execute_reply.started":"2022-11-05T16:05:54.798304Z","shell.execute_reply":"2022-11-05T16:05:54.802336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(np.argmax(y_test, axis=1), prediction, target_names=labels_new))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:54.804732Z","iopub.execute_input":"2022-11-05T16:05:54.805532Z","iopub.status.idle":"2022-11-05T16:05:54.818322Z","shell.execute_reply.started":"2022-11-05T16:05:54.805449Z","shell.execute_reply":"2022-11-05T16:05:54.817333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# predicting function","metadata":{}},{"cell_type":"code","source":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\nIMG_SIZE = 145\ndef prepare(filepath, face_cas=\"../input/prediction-images/haarcascade_frontalface_default.xml\"):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_array / 255\n    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nmodel = tf.keras.models.load_model(\"./drowiness_new6.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:54.819340Z","iopub.execute_input":"2022-11-05T16:05:54.819575Z","iopub.status.idle":"2022-11-05T16:05:54.970591Z","shell.execute_reply.started":"2022-11-05T16:05:54.819551Z","shell.execute_reply":"2022-11-05T16:05:54.969680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction \n## 0-yawn, 1-no_yawn, 2-Closed, 3-Open","metadata":{}},{"cell_type":"code","source":"# prepare(\"../input/drowsiness-dataset/train/no_yawn/1068.jpg\")\nprediction = model.predict([prepare(\"../input/drowsiness-dataset/train/no_yawn/1067.jpg\")])\nnp.argmax(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:54.972024Z","iopub.execute_input":"2022-11-05T16:05:54.972352Z","iopub.status.idle":"2022-11-05T16:05:55.145702Z","shell.execute_reply.started":"2022-11-05T16:05:54.972317Z","shell.execute_reply":"2022-11-05T16:05:55.144786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict([prepare(\"../input/drowsiness-dataset/train/Closed/_101.jpg\")])\nnp.argmax(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:55.147047Z","iopub.execute_input":"2022-11-05T16:05:55.147403Z","iopub.status.idle":"2022-11-05T16:05:55.193832Z","shell.execute_reply.started":"2022-11-05T16:05:55.147367Z","shell.execute_reply":"2022-11-05T16:05:55.192419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict([prepare(\"../input/drowsiness-dataset/train/Open/_104.jpg\")])\nnp.argmax(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:55.195179Z","iopub.execute_input":"2022-11-05T16:05:55.195524Z","iopub.status.idle":"2022-11-05T16:05:55.242662Z","shell.execute_reply.started":"2022-11-05T16:05:55.195488Z","shell.execute_reply":"2022-11-05T16:05:55.241743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict([prepare(\"../input/drowsiness-dataset/train/yawn/113.jpg\")])\nnp.argmax(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T16:05:55.244071Z","iopub.execute_input":"2022-11-05T16:05:55.244414Z","iopub.status.idle":"2022-11-05T16:05:55.293466Z","shell.execute_reply.started":"2022-11-05T16:05:55.244377Z","shell.execute_reply":"2022-11-05T16:05:55.292788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# If you like please upvote","metadata":{}}]}